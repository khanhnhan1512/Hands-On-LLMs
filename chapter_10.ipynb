{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d77e910",
   "metadata": {},
   "source": [
    "# Chapter 10 - Creating Text Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0fdb72",
   "metadata": {},
   "source": [
    "## Creating an Embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9534327",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b972a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91787ee72a9c4c2c83fbe79014de5d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f042185b9084ddfb593369c5b81a4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a3de4d27df419ca27f5cd1ebd687f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef23108927b4ad5a649c3dd453577de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994c853abeb347889358ac5c5922d115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370c3281888f4ffdb3c73d5990f01484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f00a56ac40f415cae34a89979a2f38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b8546df2f149149ff486e9763ebb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2db43a593474b96b867382b99ea3e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a95524c76d5485fb6cf9266552c0ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21f18ad36cc40709cf55997efc2b01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84646300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'One of our number will carry out your instructions minutely.',\n",
       " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b28b5d",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0511f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d124d0cfd4d4439afcbd19b77933cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa8ad0d23cd45a28b9293c2c59c85bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b89b275fa3443a287f160259de74ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f273ebbb11d47ad82578cbbed5e6847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f4c70bafaf4a2e88addb53b112ab90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd5954",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64949bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c454212",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1600bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67495791b8f141d298ab47fa2eba395c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/502k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f0fa1f7b8f4013a979348e3b0c115c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/151k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2699d438d2e431c865c105672e001f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/114k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfb178ec64e4973b9dbd7bdf9d95be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791c152e5abf49eab89b15ee326997a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898ee22a39a5491aa3c1655098043ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a4327",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5db6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2021d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fed5e7b0c3428b8137d3f9529031ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0672, 'grad_norm': 2.943986177444458, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.9489, 'grad_norm': 2.6952121257781982, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8943, 'grad_norm': 3.071946859359741, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.8535, 'grad_norm': 3.986969470977783, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.8312, 'grad_norm': 4.4188947677612305, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238109ba2c9548fe839bbd0077eec153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8539, 'grad_norm': 4.209220886230469, 'learning_rate': 3.2946001367054005e-05, 'epoch': 0.38}\n",
      "{'loss': 0.8195, 'grad_norm': 4.817514419555664, 'learning_rate': 2.9528366370471632e-05, 'epoch': 0.45}\n",
      "{'loss': 0.8066, 'grad_norm': 4.501857757568359, 'learning_rate': 2.611073137388927e-05, 'epoch': 0.51}\n",
      "{'loss': 0.8008, 'grad_norm': 5.136640548706055, 'learning_rate': 2.2693096377306907e-05, 'epoch': 0.58}\n",
      "{'loss': 0.8053, 'grad_norm': 4.59669303894043, 'learning_rate': 1.9275461380724537e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7749, 'grad_norm': 3.2648565769195557, 'learning_rate': 1.5857826384142175e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7598, 'grad_norm': 6.336752891540527, 'learning_rate': 1.2440191387559808e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7757, 'grad_norm': 3.5765745639801025, 'learning_rate': 9.022556390977444e-06, 'epoch': 0.83}\n",
      "{'loss': 0.7509, 'grad_norm': 4.3848090171813965, 'learning_rate': 5.604921394395079e-06, 'epoch': 0.9}\n",
      "{'loss': 0.777, 'grad_norm': 5.516924858093262, 'learning_rate': 2.187286397812714e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 226.4975, 'train_samples_per_second': 220.753, 'train_steps_per_second': 6.901, 'train_loss': 0.8320150686545931, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.8320150686545931, metrics={'train_runtime': 226.4975, 'train_samples_per_second': 220.753, 'train_steps_per_second': 6.901, 'total_flos': 0.0, 'train_loss': 0.8320150686545931, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68088180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.4269660344252679,\n",
       " 'spearman_cosine': 0.4889759904724608,\n",
       " 'pearson_manhattan': 0.46133627094623064,\n",
       " 'spearman_manhattan': 0.48610902052240407,\n",
       " 'pearson_euclidean': 0.4497834418965715,\n",
       " 'spearman_euclidean': 0.4802397638029282,\n",
       " 'pearson_dot': 0.3984190595159358,\n",
       " 'spearman_dot': 0.4082841892345862,\n",
       " 'pearson_max': 0.46133627094623064,\n",
       " 'spearman_max': 0.4889759904724608}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8209d682",
   "metadata": {},
   "source": [
    "## MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe03d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.evaluation.MTEB:Passing task names as strings is deprecated and will be removed in the next release. Please use `tasks = mteb.get_tasks(tasks=[...])` method to get tasks instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Classification</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClassification\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Banking77Classification, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Banking77Classification, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[MTEBResults(task_name=Banking77Classification, scores=...)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mteb import MTEB\n",
    "evaluation = MTEB(tasks=[\"Banking77Classification\"])\n",
    "\n",
    "results = evaluation.run(embedding_model)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeca4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cedd511",
   "metadata": {},
   "source": [
    "## Loss Funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa1bdf",
   "metadata": {},
   "source": [
    "### Cosine Similarity Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cb8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "mapping = {2: 0, 1: 0, 0: 1}\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"sentence1\": train_dataset[\"premise\"],\n",
    "        \"sentence2\": train_dataset[\"hypothesis\"],\n",
    "        \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e40756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores = [score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de1d6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fff56a7b4784a82be0983da1da5d3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2309, 'grad_norm': 2.236973762512207, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1694, 'grad_norm': 1.530463457107544, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1704, 'grad_norm': 1.2414125204086304, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1593, 'grad_norm': 1.0040730237960815, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1524, 'grad_norm': 1.6231491565704346, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ad719cb6764f819100fb1cf488af7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1586, 'grad_norm': 1.2467025518417358, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.15, 'grad_norm': 1.0338683128356934, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1561, 'grad_norm': 1.677746295928955, 'learning_rate': 2.6076555023923443e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1489, 'grad_norm': 1.4655015468597412, 'learning_rate': 2.2658920027341084e-05, 'epoch': 0.58}\n",
      "{'loss': 0.148, 'grad_norm': 1.0010393857955933, 'learning_rate': 1.9241285030758715e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1479, 'grad_norm': 1.3275713920593262, 'learning_rate': 1.5823650034176352e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1457, 'grad_norm': 1.3998632431030273, 'learning_rate': 1.2406015037593984e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1472, 'grad_norm': 1.4148309230804443, 'learning_rate': 8.988380041011621e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1414, 'grad_norm': 1.3700520992279053, 'learning_rate': 5.570745044429255e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1396, 'grad_norm': 1.1958560943603516, 'learning_rate': 2.15311004784689e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 219.6343, 'train_samples_per_second': 227.651, 'train_steps_per_second': 7.116, 'train_loss': 0.1571444806119073, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.1571444806119073, metrics={'train_runtime': 219.6343, 'train_samples_per_second': 227.651, 'train_steps_per_second': 7.116, 'total_flos': 0.0, 'train_loss': 0.1571444806119073, 'epoch': 1.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"cosineloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11ae4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7248499580867129,\n",
       " 'spearman_cosine': 0.7273437813071368,\n",
       " 'pearson_manhattan': 0.7384358702485685,\n",
       " 'spearman_manhattan': 0.7370732310820323,\n",
       " 'pearson_euclidean': 0.7382434313913847,\n",
       " 'spearman_euclidean': 0.7368875067545738,\n",
       " 'pearson_dot': 0.6676837171957636,\n",
       " 'spearman_dot': 0.6698132878680747,\n",
       " 'pearson_max': 0.7384358702485685,\n",
       " 'spearman_max': 0.7370732310820323}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2afd4",
   "metadata": {},
   "source": [
    "### Multiple Negative Ranking Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7dae8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f25b4fe391b48a2a42506a0fed1c2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16875it [00:00, 26569.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "mnli = mnli.remove_columns(\"idx\")\n",
    "mnli = mnli.filter(lambda x: True if x['label'] == 0 else False)\n",
    "\n",
    "train_dataset = {\"anchor\": [], \"positive\": [], \"negative\": []}\n",
    "soft_negatives = mnli[\"hypothesis\"]\n",
    "random.shuffle(soft_negatives)\n",
    "for row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n",
    "    train_dataset[\"anchor\"].append(row[\"premise\"])\n",
    "    train_dataset[\"positive\"].append(row[\"hypothesis\"])\n",
    "    train_dataset[\"negative\"].append(soft_negative)\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b436224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores = [score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f71877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f498e3292f491db73296267358ef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3371, 'grad_norm': 5.291716575622559, 'learning_rate': 4.85e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1056, 'grad_norm': 5.968145370483398, 'learning_rate': 3.866822429906542e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0774, 'grad_norm': 4.940764904022217, 'learning_rate': 2.698598130841122e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0666, 'grad_norm': 0.21554285287857056, 'learning_rate': 1.530373831775701e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0691, 'grad_norm': 1.5026662349700928, 'learning_rate': 3.6214953271028036e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abf209c566c47c6be880c862d389a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 100.9323, 'train_samples_per_second': 167.191, 'train_steps_per_second': 5.231, 'train_loss': 0.1275985473484704, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=528, training_loss=0.1275985473484704, metrics={'train_runtime': 100.9323, 'train_samples_per_second': 167.191, 'train_steps_per_second': 5.231, 'total_flos': 0.0, 'train_loss': 0.1275985473484704, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# Define model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
    "\n",
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"mnrloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "293b8f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8103973735587551,\n",
       " 'spearman_cosine': 0.8123781869653769,\n",
       " 'pearson_manhattan': 0.8244308076276949,\n",
       " 'spearman_manhattan': 0.8194081775819729,\n",
       " 'pearson_euclidean': 0.8241744954401639,\n",
       " 'spearman_euclidean': 0.8189561975709714,\n",
       " 'pearson_dot': 0.7359319321075328,\n",
       " 'spearman_dot': 0.7243260390110376,\n",
       " 'pearson_max': 0.8244308076276949,\n",
       " 'spearman_max': 0.8194081775819729}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4eda63",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de08ac0",
   "metadata": {},
   "source": [
    "### Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed22a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores = [score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37e63b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cf3202cce8472eb4c145004cad42b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ce6c8a01d04343b4be6bd37a563a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867678a88ca444558239abc48e5e0d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4672f7fcee443faaf604a5f31f7028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799756db59dc43bbaabe8fb046b31c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a452001bc8b4a67bb637efa1e68d324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63ab85250c447185ca25e1599fce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad4f9ef6304af78f8f28a40d9f96dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f1314fa22844a7afc6713eb20a4009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0214b8c6bfcd47e6aa2d394539fa564c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d3a95a9c94826a1a32dd3399d0588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72e03510ec14543a95ddf9fe56aacb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1579, 'grad_norm': 3.3383264541625977, 'learning_rate': 5e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1103, 'grad_norm': 2.0389392375946045, 'learning_rate': 4.6582365003417636e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1208, 'grad_norm': 1.8478738069534302, 'learning_rate': 4.316473000683528e-05, 'epoch': 0.19}\n",
      "{'loss': 0.116, 'grad_norm': 3.5813465118408203, 'learning_rate': 3.9747095010252904e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1104, 'grad_norm': 5.544090270996094, 'learning_rate': 3.632946001367054e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd0f81bacb94bc4be05c6a5c796559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.103, 'grad_norm': 1.4601185321807861, 'learning_rate': 3.291182501708818e-05, 'epoch': 0.38}\n",
      "{'loss': 0.112, 'grad_norm': 3.89973783493042, 'learning_rate': 2.9494190020505813e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1008, 'grad_norm': 2.8806612491607666, 'learning_rate': 2.6076555023923443e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1081, 'grad_norm': 1.9317626953125, 'learning_rate': 2.2658920027341084e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1015, 'grad_norm': 5.811153411865234, 'learning_rate': 1.9241285030758715e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0971, 'grad_norm': 3.0193395614624023, 'learning_rate': 1.5823650034176352e-05, 'epoch': 0.7}\n",
      "{'loss': 0.109, 'grad_norm': 1.5798457860946655, 'learning_rate': 1.2406015037593984e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1049, 'grad_norm': 2.923222303390503, 'learning_rate': 8.988380041011621e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1063, 'grad_norm': 1.1207858324050903, 'learning_rate': 5.570745044429255e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1075, 'grad_norm': 4.140763282775879, 'learning_rate': 2.15311004784689e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 79.9944, 'train_samples_per_second': 625.043, 'train_steps_per_second': 19.539, 'train_loss': 0.11024341961548867, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.11024341961548867, metrics={'train_runtime': 79.9944, 'train_samples_per_second': 625.043, 'train_steps_per_second': 19.539, 'total_flos': 0.0, 'train_loss': 0.11024341961548867, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"finetuned_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e325888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8486568725007678,\n",
       " 'spearman_cosine': 0.8479664072547248,\n",
       " 'pearson_manhattan': 0.8506895739059305,\n",
       " 'spearman_manhattan': 0.8469505097564902,\n",
       " 'pearson_euclidean': 0.8516261002307633,\n",
       " 'spearman_euclidean': 0.8479664072547248,\n",
       " 'pearson_dot': 0.8486568752742518,\n",
       " 'spearman_dot': 0.8479664072547248,\n",
       " 'pearson_max': 0.8516261002307633,\n",
       " 'spearman_max': 0.8479664072547248}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3186708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.8696194575405793,\n",
       " 'spearman_cosine': 0.8671631190200253,\n",
       " 'pearson_manhattan': 0.8670398996831856,\n",
       " 'spearman_manhattan': 0.8663946131522758,\n",
       " 'pearson_euclidean': 0.867871596469861,\n",
       " 'spearman_euclidean': 0.8671631190200253,\n",
       " 'pearson_dot': 0.8696194549917766,\n",
       " 'spearman_dot': 0.8671631197908374,\n",
       " 'pearson_max': 0.8696194575405793,\n",
       " 'spearman_max': 0.8671631197908374}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "evaluator(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e28b68",
   "metadata": {},
   "source": [
    "## Augmented SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4c3bd",
   "metadata": {},
   "source": [
    "**Step 1**: Fine-tune a cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec64fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 37412.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "mapping = {2: 0, 1: 0, 0: 1}\n",
    "\n",
    "gold_examples = [\n",
    "    InputExample(texts=[row[\"premise\"], row[\"hypothesis\"]], label=mapping[row[\"label\"]]) for row in tqdm(dataset)\n",
    "]\n",
    "gold_dataloader = NoDuplicatesDataLoader(gold_examples, batch_size=32)\n",
    "\n",
    "gold = pd.DataFrame(\n",
    "    {\n",
    "        'sentence1': dataset['premise'],\n",
    "        'sentence2': dataset['hypothesis'],\n",
    "        'label': [mapping[label] for label in dataset['label']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48f1b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a31307f50d940e9956ec20b4af4cb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06025c7bdbe3448b84b766b8e308aba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder('bert-base-uncased', num_labels=2)\n",
    "cross_encoder.fit(\n",
    "    train_dataloader=gold_dataloader,\n",
    "    epochs=1, show_progress_bar=True,\n",
    "    warmup_steps=100,\n",
    "    use_amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff6ef8",
   "metadata": {},
   "source": [
    "**Step 2**: Create a new sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(10_000, 50_000))\n",
    "pairs = list(zip(silver['premise'], silver['hypothesis']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbf2ce",
   "metadata": {},
   "source": [
    "**Step 3**: Label new sentence pairs with the fine-tuned cross-encoder (silver dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e925df2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7712feef8f07466b921aef6c8a6a59e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = cross_encoder.predict(pairs, apply_softmax=True, show_progress_bar=True)\n",
    "silver = pd.DataFrame(\n",
    "    {\n",
    "        'sentence1': silver['premise'],\n",
    "        'sentence2': silver['hypothesis'],\n",
    "        'label': np.argmax(output, axis=1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9a950",
   "metadata": {},
   "source": [
    "**Step 4**: Train a bi-encoder (SBERT) on the extended datatset (gold + silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a4d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine gold and silver\n",
    "data = pd.concat([gold, silver], ignore_index=True, axis=0)\n",
    "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep='first')\n",
    "train_dataset = Dataset.from_pandas(data, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199da462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores = [score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41139f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40840eb284284f0ba9bf383d9a277d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2354, 'grad_norm': 1.6784230470657349, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1737, 'grad_norm': 1.5096228122711182, 'learning_rate': 4.6616541353383456e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1636, 'grad_norm': 1.6863032579421997, 'learning_rate': 4.3198906356801096e-05, 'epoch': 0.19}\n",
      "{'loss': 0.163, 'grad_norm': 1.2168338298797607, 'learning_rate': 3.978127136021873e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1565, 'grad_norm': 1.3421708345413208, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01c8081cc3432f873911b7a1b541c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1579, 'grad_norm': 1.5156283378601074, 'learning_rate': 3.2946001367054005e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1523, 'grad_norm': 1.292264699935913, 'learning_rate': 2.9528366370471632e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1518, 'grad_norm': 1.2168147563934326, 'learning_rate': 2.611073137388927e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1482, 'grad_norm': 1.4321715831756592, 'learning_rate': 2.2693096377306907e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1453, 'grad_norm': 1.3003636598587036, 'learning_rate': 1.9275461380724537e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1512, 'grad_norm': 1.1824214458465576, 'learning_rate': 1.5857826384142175e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1456, 'grad_norm': 1.1237597465515137, 'learning_rate': 1.2440191387559808e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1446, 'grad_norm': 1.3558070659637451, 'learning_rate': 9.022556390977444e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1458, 'grad_norm': 1.2280879020690918, 'learning_rate': 5.604921394395079e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1445, 'grad_norm': 1.0700139999389648, 'learning_rate': 2.187286397812714e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 222.6153, 'train_samples_per_second': 224.594, 'train_steps_per_second': 7.021, 'train_loss': 0.15777476842176127, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.15777476842176127, metrics={'train_runtime': 222.6153, 'train_samples_per_second': 224.594, 'train_steps_per_second': 7.021, 'total_flos': 0.0, 'train_loss': 0.15777476842176127, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"augmented_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efed2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7340504370447386,\n",
       " 'spearman_cosine': 0.7367061543162533,\n",
       " 'pearson_manhattan': 0.73860755719696,\n",
       " 'spearman_manhattan': 0.7389655817992703,\n",
       " 'pearson_euclidean': 0.7384506413601905,\n",
       " 'spearman_euclidean': 0.7385994420996997,\n",
       " 'pearson_dot': 0.7008053852029055,\n",
       " 'spearman_dot': 0.7026937642958971,\n",
       " 'pearson_max': 0.73860755719696,\n",
       " 'spearman_max': 0.7389655817992703}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a68825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.accelerator.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae9339",
   "metadata": {},
   "source": [
    "**Step 5**: Evaluate without the silver dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da95009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85ef08e86154064b1895213d51b2cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2354, 'grad_norm': 1.6784230470657349, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1737, 'grad_norm': 1.5096228122711182, 'learning_rate': 4.6616541353383456e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1636, 'grad_norm': 1.6834665536880493, 'learning_rate': 4.3198906356801096e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1627, 'grad_norm': 1.2431890964508057, 'learning_rate': 3.978127136021873e-05, 'epoch': 0.26}\n",
      "{'loss': 0.157, 'grad_norm': 1.2910016775131226, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db14dec83e04f30a1525d2267864c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1576, 'grad_norm': 1.490830421447754, 'learning_rate': 3.2946001367054005e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1518, 'grad_norm': 1.2361739873886108, 'learning_rate': 2.9528366370471632e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1512, 'grad_norm': 1.2147853374481201, 'learning_rate': 2.611073137388927e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1491, 'grad_norm': 1.3431299924850464, 'learning_rate': 2.2693096377306907e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1456, 'grad_norm': 1.3120659589767456, 'learning_rate': 1.9275461380724537e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1509, 'grad_norm': 1.154739260673523, 'learning_rate': 1.5857826384142175e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1456, 'grad_norm': 1.1382807493209839, 'learning_rate': 1.2440191387559808e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1444, 'grad_norm': 1.3839597702026367, 'learning_rate': 9.022556390977444e-06, 'epoch': 0.83}\n",
      "{'loss': 0.1455, 'grad_norm': 1.2133880853652954, 'learning_rate': 5.604921394395079e-06, 'epoch': 0.9}\n",
      "{'loss': 0.1444, 'grad_norm': 1.0826623439788818, 'learning_rate': 2.187286397812714e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 235.1198, 'train_samples_per_second': 212.649, 'train_steps_per_second': 6.648, 'train_loss': 0.15768708102762585, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1563, training_loss=0.15768708102762585, metrics={'train_runtime': 235.1198, 'train_samples_per_second': 212.649, 'train_steps_per_second': 6.648, 'total_flos': 0.0, 'train_loss': 0.15768708102762585, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([gold], ignore_index=True, axis=0)\n",
    "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep=\"first\")\n",
    "train_dataset = Dataset.from_pandas(data, preserve_index=False)\n",
    "\n",
    "# Define model\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"gold_only_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d37a09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7391174644133511,\n",
       " 'spearman_cosine': 0.7415088480221026,\n",
       " 'pearson_manhattan': 0.741650970678973,\n",
       " 'spearman_manhattan': 0.7422510745129687,\n",
       " 'pearson_euclidean': 0.7415154616689631,\n",
       " 'spearman_euclidean': 0.7421394641156605,\n",
       " 'pearson_dot': 0.6962311529189662,\n",
       " 'spearman_dot': 0.6991862102738733,\n",
       " 'pearson_max': 0.741650970678973,\n",
       " 'spearman_max': 0.7422510745129687}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59a798",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "### Transfomer-based Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303ec81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd2fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48353/48353 [00:06<00:00, 7395.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n",
    "\n",
    "# Create a flat list of sentences\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(25_000))\n",
    "flat_sentences = mnli[\"premise\"] + mnli[\"hypothesis\"]\n",
    "\n",
    "# Add noise to our input data\n",
    "damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = {\"damaged_sentence\": [], \"original_sentence\": []}\n",
    "for data in tqdm(damaged_data):\n",
    "    train_dataset[\"damaged_sentence\"].append(data.texts[0])\n",
    "    train_dataset[\"original_sentence\"].append(data.texts[1])\n",
    "train_dataset = Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e25d915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'damaged_sentence': 'it Paris in winter.',\n",
       " 'original_sentence': \"it's best to visit Paris in winter.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f32bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores = [score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc0ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "word_embedding_model = models.Transformer('bert-base-uncased')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdca90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    embedding_model, tie_encoder_decoder=True\n",
    ")\n",
    "train_loss.decoder = train_loss.decoder.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5398f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\accelerate\\accelerator.py:477: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6756cd8eed84501a303b19ff28f0629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.1498, 'grad_norm': 10.996194839477539, 'learning_rate': 4.8e-05, 'epoch': 0.03}\n",
      "{'loss': 4.9324, 'grad_norm': 7.21999454498291, 'learning_rate': 4.8357851522408484e-05, 'epoch': 0.07}\n",
      "{'loss': 4.697, 'grad_norm': 6.95160436630249, 'learning_rate': 4.6647280191583994e-05, 'epoch': 0.1}\n",
      "{'loss': 4.5951, 'grad_norm': 7.555102825164795, 'learning_rate': 4.49367088607595e-05, 'epoch': 0.13}\n",
      "{'loss': 4.5318, 'grad_norm': 6.254870891571045, 'learning_rate': 4.3226137529935e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba8df045a994387bd8d99273f148eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3859, 'grad_norm': 6.634369850158691, 'learning_rate': 4.15155661991105e-05, 'epoch': 0.2}\n",
      "{'loss': 4.385, 'grad_norm': 6.556199073791504, 'learning_rate': 3.980499486828601e-05, 'epoch': 0.23}\n",
      "{'loss': 4.3271, 'grad_norm': 6.527666091918945, 'learning_rate': 3.8094423537461516e-05, 'epoch': 0.26}\n",
      "{'loss': 4.2473, 'grad_norm': 7.25576114654541, 'learning_rate': 3.638385220663702e-05, 'epoch': 0.3}\n",
      "{'loss': 4.271, 'grad_norm': 5.7785844802856445, 'learning_rate': 3.467328087581252e-05, 'epoch': 0.33}\n",
      "{'loss': 4.2067, 'grad_norm': 6.272899150848389, 'learning_rate': 3.296270954498803e-05, 'epoch': 0.36}\n",
      "{'loss': 4.1692, 'grad_norm': 6.672155857086182, 'learning_rate': 3.1252138214163535e-05, 'epoch': 0.4}\n",
      "{'loss': 4.1783, 'grad_norm': 6.597072601318359, 'learning_rate': 2.9541566883339038e-05, 'epoch': 0.43}\n",
      "{'loss': 4.0809, 'grad_norm': 6.397854328155518, 'learning_rate': 2.7830995552514545e-05, 'epoch': 0.46}\n",
      "{'loss': 4.1572, 'grad_norm': 6.906569480895996, 'learning_rate': 2.6120424221690044e-05, 'epoch': 0.5}\n",
      "{'loss': 4.061, 'grad_norm': 6.433307647705078, 'learning_rate': 2.440985289086555e-05, 'epoch': 0.53}\n",
      "{'loss': 4.0366, 'grad_norm': 6.646346569061279, 'learning_rate': 2.2699281560041054e-05, 'epoch': 0.56}\n",
      "{'loss': 3.9714, 'grad_norm': 6.474647521972656, 'learning_rate': 2.098871022921656e-05, 'epoch': 0.6}\n",
      "{'loss': 4.0197, 'grad_norm': 7.374326705932617, 'learning_rate': 1.9278138898392063e-05, 'epoch': 0.63}\n",
      "{'loss': 3.9728, 'grad_norm': 7.860544681549072, 'learning_rate': 1.756756756756757e-05, 'epoch': 0.66}\n",
      "{'loss': 3.9687, 'grad_norm': 7.122493267059326, 'learning_rate': 1.5856996236743073e-05, 'epoch': 0.69}\n",
      "{'loss': 3.9104, 'grad_norm': 6.37161922454834, 'learning_rate': 1.4146424905918579e-05, 'epoch': 0.73}\n",
      "{'loss': 3.9428, 'grad_norm': 7.6796417236328125, 'learning_rate': 1.2435853575094082e-05, 'epoch': 0.76}\n",
      "{'loss': 3.9172, 'grad_norm': 6.423492908477783, 'learning_rate': 1.0725282244269587e-05, 'epoch': 0.79}\n",
      "{'loss': 3.8858, 'grad_norm': 6.3235602378845215, 'learning_rate': 9.014710913445092e-06, 'epoch': 0.83}\n",
      "{'loss': 3.8928, 'grad_norm': 7.952090263366699, 'learning_rate': 7.304139582620595e-06, 'epoch': 0.86}\n",
      "{'loss': 3.8689, 'grad_norm': 8.714198112487793, 'learning_rate': 5.5935682517961e-06, 'epoch': 0.89}\n",
      "{'loss': 3.9124, 'grad_norm': 7.727043628692627, 'learning_rate': 3.882996920971604e-06, 'epoch': 0.93}\n",
      "{'loss': 3.8212, 'grad_norm': 7.001772403717041, 'learning_rate': 2.1724255901471093e-06, 'epoch': 0.96}\n",
      "{'loss': 3.893, 'grad_norm': 7.883581161499023, 'learning_rate': 4.6185425932261374e-07, 'epoch': 0.99}\n",
      "{'train_runtime': 455.3723, 'train_samples_per_second': 106.183, 'train_steps_per_second': 6.639, 'train_loss': 4.243638261043587, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3023, training_loss=4.243638261043587, metrics={'train_runtime': 455.3723, 'train_samples_per_second': 106.183, 'train_steps_per_second': 6.639, 'total_flos': 0.0, 'train_loss': 4.243638261043587, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"tsdae_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b205f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.6755061908100044,\n",
       " 'spearman_cosine': 0.6907158912611558,\n",
       " 'pearson_manhattan': 0.6907605506750119,\n",
       " 'spearman_manhattan': 0.6952479406521168,\n",
       " 'pearson_euclidean': 0.6915512320822095,\n",
       " 'spearman_euclidean': 0.6956817042966573,\n",
       " 'pearson_dot': 0.5117403919131931,\n",
       " 'spearman_dot': 0.49990595575508096,\n",
       " 'pearson_max': 0.6915512320822095,\n",
       " 'spearman_max': 0.6956817042966573}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
