{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d678b684",
   "metadata": {},
   "source": [
    "# Chapter 7 - Advanced Text Generation Techniques and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e882d",
   "metadata": {},
   "source": [
    "## Loading an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4745ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LlamaCpp\n",
    "\n",
    "llm =  LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=512,\n",
    "    n_ctx=2048,\n",
    "    seed=42,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b191ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Hi! My name is Nhan. What is 1 + 1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b760f",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c998358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"<s><|user|>\n",
    "{input_prompt}<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input_prompt\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_chain = prompt | llm\n",
    "basic_chain.invoke(\n",
    "    {\n",
    "        \"input_prompt\": \"Hi! My name is Nhan. What is 1 + 1?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944d173",
   "metadata": {},
   "source": [
    "### Multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ea740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "template = \"\"\"<s><|user|>\n",
    "Create a title for a story about {summary}. Only return the title.<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "title_prompt = PromptTemplate(template=template, input_variables=[\"summary\"])\n",
    "title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.invoke({\"summary\": \"a girl that lost her mother\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<s><|user|>\n",
    "Describe the main character of a story about {summary} with the title {title}. Use only two sentences.<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "character_prompt = PromptTemplate(template=template, input_variables=[\"summary\", \"title\"])\n",
    "character = LLMChain(llm=llm, prompt=character_prompt, output_key=\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<s><|user|>\n",
    "Create a story about {summary} with the title {title}. The main character is: {character}. Only return the story and it can't be longer than one paragraph<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "story_prompt = PromptTemplate(template=template, input_variables=[\"summary\", \"title\", \"character\"])\n",
    "story = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75176373",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = title | character | story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke(\"a girl that lost her mother\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112740cf",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_chain.invoke({\"input_prompt\": \"Hi! My name is Nhan. What is 1 + 1?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec07b7",
   "metadata": {},
   "source": [
    "### ConversationBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9245bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<s><|user|>Current conversation:{chat_history}\n",
    "\n",
    "{input_prompt}<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input_prompt\", \"chat_history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8313874",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"input_prompt\": \"Hi! My name is Nhan. What is 1+1?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f32831",
   "metadata": {},
   "source": [
    "### ConversationBufferMemoryWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"input_prompt\": \"Hi! My name is Maarten and I am 22 years old. What is 1 + 1?\"})\n",
    "llm_chain.invoke({\"input_prompt\": \"What is 3 + 3?\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9011ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke({\"input_prompt\": \"What is my age?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7880f",
   "metadata": {},
   "source": [
    "### ConversationSummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt_template = \"\"\"<s><|user|>Summarize the conversation and update with the new lines.\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"new_lines\", \"summary\"],\n",
    "    template=summary_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35964d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    prompt=summary_prompt\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3641eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c213a",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6135c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d14ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_template = \"\"\"Answer the following questions as best you can. You have to access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Though: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=react_template,\n",
    "    input_variables=[\"input\", \"tools\", \"tool_names\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac60b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, Tool\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "search_tool = Tool(\n",
    "    name=\"duckduck\",\n",
    "    description=\"A web search engine. Use this to as a search engine for general quesries.\",\n",
    "    func=search.run\n",
    ")\n",
    "\n",
    "tools = load_tools([\"llm-math\"], llm=openai_llm)\n",
    "tools.append(search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b49f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "agent = create_react_agent(openai_llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d79ac6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use a web search engine to find the current price of a MacBook Pro in USD and then use a calculator to convert it to EUR.\n",
      "Action: duckduck\n",
      "Action Input: \"current price of MacBook Pro in USD\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: UserWarning: 'api' backend is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m[snippet: The base model of the M3 Pro starts at $2,499 USD (although exclusive discounts are available in this guide) and is an ideal option for users who want a larger screen and advanced capabilities. To get the best deal on this or any other MacBook Pro, check out AppleInsider's list of the top MacBook Pro deals., title: MacBook Pro 16-inch Best Price M3 Max, 16C CPU, 40C GPU, 48GB, 1TB ..., link: https://prices.appleinsider.com/product/macbook-pro-16-inch-m3/MUW63LL/A], [snippet: For a limited time, you can get the M4 MacBook Pro (Silver) for $1,373 from go-to Apple retailer, Amazon. That's $226 below the M4 MB Pro's $1,599 list price and just $1 shy of its all-time low., title: Apple's excellent M4 MacBook Pro hits all-time low price - Laptop Mag, link: https://www.laptopmag.com/deals/laptops/macbooks/the-5-star-rated-m4-macbook-pro-dips-to-usd1-373-at-amazon], [snippet: With power, performance, and premium style, the MacBook Pro represents the pinnacle of Apple's laptop offerings. This comprehensive guide breaks down current MacBook Pro pricing across available sizes, processors, storage capacities, and more. You'll learn how choices at checkout impact final cost, find savings opportunities, and gain insight into Apple's pricing philosophy on its professional ..., title: How Much Does a MacBook Pro Cost? - The Pricer, link: https://www.thepricer.org/how-much-does-a-macbook-pro-cost/], [snippet: Apple's MacBook Pro 14-inch with M3 replaces the aging 13-inch model. Retail prices start at $1,599 with the M3 processor, 8GB of RAM, and 512GB of storage, although the MacBook Pro deals in this Price Guide can knock up to $200 off the Late 2023 models. Looking for the higher end M3 Pro and M3 Max models?, title: M3 MacBook Pro 14-inch 2023 Best Sale Price Deals Discounts, link: https://prices.appleinsider.com/macbook-pro-14-inch-m3]\u001b[0m\u001b[32;1m\u001b[1;3mI should click on one of the search results to find the current price of a MacBook Pro in USD.\n",
      "Action: duckduck\n",
      "Action Input: click on the link \"MacBook Pro 16-inch Best Price M3 Max, 16C CPU, 40C GPU, 48GB, 1TB ...\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\LLMs-env\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: UserWarning: 'api' backend is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m[snippet: Apple launched its 16-inch M3 MacBook Pro in late 2023, alongside the smaller 14-inch model. This new MacBook Pro lineup is powered by M3 Pro and M3 Max chipsets, both of which offer significant performance enhancements compared to the M1 and M2 MacBook Pros. The 16-inch M3 MacBook Pro is available in Space Black or Silver., title: MacBook Pro 16-inch Best Price M3 Max, 16C CPU, 40C GPU, 48GB, 1TB ..., link: https://prices.appleinsider.com/product/macbook-pro-16-inch-m3/MUW63LL/A], [snippet: Disclosure: If you buy through our links, we may earn commission as an affiliate & Amazon Associate. Apple's MacBook Pro 16-inch with M3 Pro and M3 Max is its largest and most powerful MacBook available. It starts at $2,499 with the M3 Pro processor, 18GB of RAM, and 512GB of storage., title: M3 MacBook Pro 16-Inch 2023 Best Sale Price Deals - AppleInsider, link: https://prices.appleinsider.com/macbook-pro-16-inch-m3], [snippet: Best Buy has clearance 16″ M3 Max Apple MacBook Pros on sale for $700-$800 off original MSRP on their online store right now. Prices valid for online orders only, in-store prices may vary. Order online and choose free shipping or free local store pickup (if available): - 16″ M3 Max MacBook Pro (36GB/1TB): $2799, $700 off MSRP, title: Clearance 16-inch M3 Max MacBook Pros on sale for $700-$800 off MSRP, link: https://www.macprices.net/2025/03/20/clearance-16-inch-m3-max-macbook-pros-on-sale-for-700-800-off-msrp/], [snippet: Do not miss the $500 price drop on the MacBook Pro 16\" M3 Max. The perfect time to buy a powerful machine at Best Buy. Apple's 2025 Lineup iOS 19 iPhone 17 News Deals Round-Ups How-To Jobs, title: MacBook Pro 16″ M3 Max (48GB, 1TB) Gets a $500 Price Drop at Best Buy, link: https://www.macobserver.com/deals/macbook-pro-16-m3-max-48gb-1tb-gets-a-500-price-drop-at-best-buy/]\u001b[0m\u001b[32;1m\u001b[1;3mI should note down the price of the MacBook Pro in USD, which is $2,499.\n",
      "Action: Calculator\n",
      "Action Input: 2499 * 0.85\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 2124.15\u001b[0m\u001b[32;1m\u001b[1;3mI now know that the current price of a MacBook Pro in USD is $2,499 and it would cost 2124.15 EUR with an exchange rate of 0.85 EUR for 1 USD.\n",
      "Final Answer: The current price of a MacBook Pro in USD is $2,499 and it would cost 2124.15 EUR with an exchange rate of 0.85 EUR for 1 USD.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the current price of a MacBook Pro in USD? How much would it cost in EUR if the exchange rate is 0.85 EUR for 1 USD?',\n",
       " 'output': 'The current price of a MacBook Pro in USD is $2,499 and it would cost 2124.15 EUR with an exchange rate of 0.85 EUR for 1 USD.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the current price of a MacBook Pro in USD? How much would it cost in EUR if the exchange rate is 0.85 EUR for 1 USD?\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
